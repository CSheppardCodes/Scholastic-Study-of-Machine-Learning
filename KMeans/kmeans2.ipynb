{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNh3EbqqXk0KkH1TBfZlmsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSheppardCodes/Study-of-Machine-Learning/blob/main/KMeans/kmeans2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFcGjuKpMqiR",
        "outputId": "8c98b734-5e3d-4211-ff05-af7bb4ac550f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 1\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 2\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 3\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 4\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 5\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 6\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 7\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 8\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "Running iteration 9\n",
            "Cluster 0 has computed a new centroid\n",
            "Cluster 1 has computed a new centroid\n",
            "Cluster 2 has computed a new centroid\n",
            "Cluster 3 has computed a new centroid\n",
            "Cluster 4 has computed a new centroid\n",
            "SSE: 3525.472381908268\n",
            "909 entries for cluster centered around: older cancer patients written off\n",
            "1271 entries for cluster centered around: gay blood ban a matter for hunt\n",
            "587 entries for cluster centered around: audio safe or not statins debated\n",
            "466 entries for cluster centered around: care staff miss out on minimum pay\n",
            "696 entries for cluster centered around: stem cell scientist misled world\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import math\n",
        "import string\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "import re\n",
        "\n",
        "def preprocess(file):\n",
        "    file = file.drop(columns=[\"A\", \"B\"])\n",
        "    for idx, val in file.iterrows():\n",
        "        file.loc[idx, \"Tweet\"] = re.sub(r\"(?:\\@|http?\\://)\\S+\", \"\", file.loc[idx, \"Tweet\"]) # Removes @ and website\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].replace(\"#\", \"\") # Removes hashtags\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].replace(\"@\", \"\") # Removes remaining @ symbols\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].lower() # Converts into lowercase\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].strip() # Removes leading and trailing whitespaces\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].translate(str.maketrans('', '', string.punctuation)) # Removes puncuation characters\n",
        "        file.loc[idx, \"Tweet\"] = file.loc[idx, \"Tweet\"].replace(\"  \", \" \") # Removes double spaces\n",
        "    return file\n",
        "\n",
        "def jacardDistance(A, B):\n",
        "    # From the formula provided\n",
        "    return 1 - ((len(A.intersection(B)))/(len(A.union(B))))\n",
        "\n",
        "def k_means(tweets, k, max_iter):\n",
        "\n",
        "    centroids = []\n",
        "    prevCentroids = [\"a\"]\n",
        "\n",
        "    # Finds k random tweets to serve as the initial centroids\n",
        "    temp = rd.sample(range(0, len(tweets) - 1), k)\n",
        "    for i in range(0, len(temp)):\n",
        "        centroids.append(tweets.loc[temp[i], \"Tweet\"])\n",
        "\n",
        "    iter = 0\n",
        "\n",
        "    while (convergenceCheck(centroids, prevCentroids) == False and iter < max_iter):\n",
        "        print(\"Running iteration \" + str(iter))\n",
        "        clusters = assignClusters(tweets, centroids)\n",
        "        prevCentroids = copy.deepcopy(centroids)\n",
        "        centroids = updateCentroids(clusters, centroids, k)\n",
        "        iter+=1\n",
        "        # print(centroids)\n",
        "        # print(prevCentroids)\n",
        "\n",
        "    print(\"SSE: \" + str(computeError(clusters)))\n",
        "\n",
        "    for i in range(0, k):\n",
        "        print(str(len(clusters[i])) + \" entries for cluster centered around: \" + centroids[i])\n",
        "\n",
        "def assignClusters(tweets, centroids):\n",
        "\n",
        "    clusters = dict()\n",
        "\n",
        "    for i in range(len(tweets)):\n",
        "        A = set(tweets.loc[i, \"Tweet\"].split(\" \")) # For computing Jacard Distance\n",
        "        leastDistance = 2 # Every Jacard Distance will be [0,1]\n",
        "        for j in range(len(centroids)):\n",
        "            # print(centroids[j])\n",
        "            B = set(centroids[j].split(\" \")) # For computing Jacard Distance\n",
        "\n",
        "            currDistance = jacardDistance(A, B) # Find the nearest centroid\n",
        "            if (currDistance < leastDistance):\n",
        "                leastDistance = currDistance # Assign current nearest centroid\n",
        "                currCluster = j # Assign current nearest cluster number\n",
        "                # print(leastDistance)\n",
        "        if leastDistance == 1: # If it can't find one, assign it to a random one\n",
        "            currCluster = rd.randint(0, len(centroids) - 1)\n",
        "        clusters.setdefault(currCluster, []).append([tweets.loc[i, \"Tweet\"]]) # Add the tweet and cluster pair\n",
        "        idx = len(clusters.setdefault(currCluster, [])) - 1\n",
        "        clusters.setdefault(currCluster, [])[idx].append(leastDistance) # Also include the distance from the nearest cluster for calculating error\n",
        "        # if leastDistance != 1:\n",
        "        #     print(clusters.loc[i, \"Tweet\"])\n",
        "        #     print(clusters.loc[i, \"Cluster\"])\n",
        "        #     print(leastDistance)\n",
        "    return clusters\n",
        "\n",
        "def updateCentroids(clusters, centroids, k):\n",
        "\n",
        "    dis = 0\n",
        "    currSum = 0\n",
        "\n",
        "    newCentroids = []\n",
        "    # for i in range(0, k):\n",
        "    #     cluster.append(clusters[clusters[\"Cluster\"] == centroids[i]])\n",
        "    #     cluster[i].reset_index(inplace=True)\n",
        "    #     # print(len(cluster[i].index))\n",
        "\n",
        "\n",
        "    for i in range(0, k):\n",
        "        minDistArr = []\n",
        "        minDist = math.inf\n",
        "        idx = -1\n",
        "\n",
        "        max = len(clusters[i])\n",
        "        max = int(max)\n",
        "\n",
        "        for j in range(0, max):\n",
        "            minDistArr.append([]) # DP calculations\n",
        "            currSum = 0\n",
        "            for k in range(0, max):\n",
        "                if j != k:\n",
        "                    if k < j:\n",
        "                        dis = minDistArr[k][j] # DP\n",
        "                    else:\n",
        "                        A = set(tweets.loc[j, \"Tweet\"].split(\" \"))\n",
        "                        B = set(tweets.loc[k, \"Tweet\"].split(\" \"))\n",
        "                        # print(A)\n",
        "                        # print(B)\n",
        "                        dis = jacardDistance(A, B) # Calculate the distance between every tweet\n",
        "                    minDistArr[j].append(dis)\n",
        "                    currSum += dis # Add the distances up\n",
        "                else:\n",
        "                    minDistArr[j].append(0)\n",
        "\n",
        "            if currSum < minDist: # Find the tweet with the lowest distance\n",
        "                minDist = currSum\n",
        "                idx = j\n",
        "        # print(clusters[centroids[i]][idx])\n",
        "        newCentroids.append(clusters[i][idx][0])\n",
        "        print(\"Cluster \" + str(i) + \" has computed a new centroid\")\n",
        "    return newCentroids\n",
        "\n",
        "def convergenceCheck(centroidsA, centroidsB):\n",
        "    # If the centroids haven't changed then k-means has converged\n",
        "    for i in range(0, len(centroidsA)):\n",
        "        if centroidsA[i] != centroidsB[i]:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def computeError(clusters):\n",
        "    # From the formula provided\n",
        "    sse = 0\n",
        "    for i in range(len(clusters)):\n",
        "        for j in range(0, len(clusters[i])):\n",
        "            # print(clusters[i][j][1])\n",
        "            sse += clusters[i][j][1] * clusters[i][j][1]\n",
        "            # print(sse)\n",
        "    return sse\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    col_names = [\"A\",\"B\",\"Tweet\"]\n",
        "    file = pd.read_csv(\"https://raw.githubusercontent.com/CSheppardCodes/MLDatasetsUCI/main/asg3/bbchealth.txt\", delimiter=\"|\", names=col_names)\n",
        "    tweets = preprocess(file)\n",
        "\n",
        "    k = 5\n",
        "    max_iter = 10\n",
        "\n",
        "    k_means(tweets, k, max_iter)"
      ]
    }
  ]
}
