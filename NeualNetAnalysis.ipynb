{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO0bIQ55+9hJ7YcwXPByFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSheppardCodes/Scholastic-Study-of-Machine-Learning/blob/main/NeualNetAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXWQwsQTSQom"
      },
      "outputs": [],
      "source": [
        "#####################################################################################################################\n",
        "#    Neural Network Analysis\n",
        "#    needs dataset\n",
        "#####################################################################################################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "# , Activation,Layer,Lambda\n",
        "\n",
        "\n",
        "class NeuralNet:\n",
        "    def __init__(self, dataFile, header=True):\n",
        "        self.raw_input = pd.read_csv(dataFile, header = None)\n",
        "        self.MSE_train = []\n",
        "        self.MSE_test = []\n",
        "        self.r2_train = []\n",
        "        self.r2_test = []\n",
        "\n",
        "    # code for pre-processing the dataset, which would include standardization, normalization,\n",
        "    #   categorical to numerical, etc\n",
        "    def checkRemoveDuplicates(self, data):\n",
        "        print(\"Number of duplicated records in given data: \", data.duplicated().sum())\n",
        "        data = data.drop_duplicates()\n",
        "        return data\n",
        "\n",
        "    def checkReplaceNull(self, data):\n",
        "        print(\"Number of null values in given data: \", data.isnull().sum().sum())\n",
        "        return data\n",
        "\n",
        "    def encodeY(self, data, column):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        data.iloc[:, column] = le.fit_transform(data.iloc[:, column])\n",
        "        return data\n",
        "\n",
        "    def preprocess(self):\n",
        "        remDup = self.checkRemoveDuplicates(self.raw_input)\n",
        "        remNull = self.checkReplaceNull(remDup)\n",
        "        self.processed_data = self.encodeY(remNull, 0)\n",
        "        return 0\n",
        "\n",
        "    #  Train and evaluate models for all combinations of parameters\n",
        "    # specified. We would like to obtain following outputs:\n",
        "    #   1. Training Accuracy and Error (Loss) for every model\n",
        "    #   2. Test Accuracy and Error (Loss) for every model\n",
        "    #   3. History Curve (Plot of Accuracy against training steps) for all\n",
        "    #       the models in a single plot. The plot should be color coded i.e.\n",
        "    #       different color for each model\n",
        "\n",
        "    def splitAttributs(self, data, column):\n",
        "        X = data.iloc[:, data.columns != column]\n",
        "        Y = data.iloc[:, data.columns == column]\n",
        "        return (X, Y)\n",
        "\n",
        "    def train_model(self, act_fn, l_rate, epoch):\n",
        "        model1 = Sequential()\n",
        "        if(self.num_hidden_layers == 2):\n",
        "            hidden_dim=[16,6,3,1]\n",
        "        elif(self.num_hidden_layers == 3):\n",
        "            hidden_dim=[16,6,4,2,1]\n",
        "\n",
        "        for i in range(1,len(hidden_dim)-1):\n",
        "            if (i==1):\n",
        "                model1.add(Dense(hidden_dim[i], input_dim = hidden_dim[0], kernel_initializer = \"normal\", activation = act_fn))\n",
        "            else:\n",
        "                model1.add(Dense(hidden_dim[i], activation = act_fn))\n",
        "        model1.add(Dense(hidden_dim[-1]))\n",
        "        model1.compile(loss = \"mean_squared_error\", optimizer = optimizers.Adam(learning_rate = l_rate), metrics = [\"accuracy\"])\n",
        "\n",
        "        model1.fit(np.array(self.X_train),np.array(self.y_train),epochs = epoch)\n",
        "        pred1_train = model1.predict(np.array(self.X_train))\n",
        "        self.MSE_train.append(np.sqrt(mean_squared_error(self.y_train,pred1_train)))\n",
        "        self.r2_train.append(r2_score(self.y_train,pred1_train))\n",
        "\n",
        "        pred1_test = model1.predict(np.array(self.X_test))\n",
        "        self.MSE_test.append(np.sqrt(mean_squared_error(self.y_test,pred1_test)))\n",
        "        self.r2_test.append(r2_score(self.y_test,pred1_test))\n",
        "\n",
        "    def train_evaluate(self):\n",
        "        X, y = self.splitAttributs(self.processed_data, 0)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y)\n",
        "\n",
        "        # Below are the hyperparameters that you need to use for model evaluation\n",
        "        activations = ['logistic', 'tanh', 'relu']\n",
        "        learning_rate = [0.01, 0.1]\n",
        "        max_iterations = [100, 200] # also known as epochs\n",
        "        num_hidden_layers = [2, 3]\n",
        "\n",
        "        self.num_hidden_layers = 2\n",
        "        self.train_model(\"sigmoid\", 0.01, 100)\n",
        "        self.train_model(\"sigmoid\", 0.01, 200)\n",
        "        self.train_model(\"sigmoid\", 0.1, 100)\n",
        "        self.train_model(\"sigmoid\", 0.1, 200)\n",
        "        self.train_model(\"tanh\", 0.01, 100)\n",
        "        self.train_model(\"tanh\", 0.01, 200)\n",
        "        self.train_model(\"tanh\", 0.1, 100)\n",
        "        self.train_model(\"tanh\", 0.1, 200)\n",
        "        self.train_model(\"relu\", 0.01, 100)\n",
        "        self.train_model(\"relu\", 0.01, 200)\n",
        "        self.train_model(\"relu\", 0.1, 100)\n",
        "        self.train_model(\"relu\", 0.1, 200)\n",
        "\n",
        "        self.num_hidden_layers = 3\n",
        "        self.train_model(\"sigmoid\", 0.01, 100)\n",
        "        self.train_model(\"sigmoid\", 0.01, 200)\n",
        "        self.train_model(\"sigmoid\", 0.1, 100)\n",
        "        self.train_model(\"sigmoid\", 0.1, 200)\n",
        "        self.train_model(\"tanh\", 0.01, 100)\n",
        "        self.train_model(\"tanh\", 0.01, 200)\n",
        "        self.train_model(\"tanh\", 0.1, 100)\n",
        "        self.train_model(\"tanh\", 0.1, 200)\n",
        "        self.train_model(\"relu\", 0.01, 100)\n",
        "        self.train_model(\"relu\", 0.01, 200)\n",
        "        self.train_model(\"relu\", 0.1, 100)\n",
        "        self.train_model(\"relu\", 0.1, 200)\n",
        "\n",
        "        # Create the neural network and be sure to keep track of the performance metrics\n",
        "\n",
        "        activations = ['logistic','logistic','logistic','logistic','tanh','tanh','tanh','tanh','relu','relu','relu','relu',\\\n",
        "                        'logistic','logistic','logistic','logistic','tanh','tanh','tanh','tanh','relu','relu','relu','relu',]\n",
        "        learning_rate = [0.01,0.01,0.1,0.1,0.01,0.01,0.1,0.1,0.01,0.01,0.1,0.1,\\\n",
        "                            0.01,0.01,0.1,0.1,0.01,0.01,0.1,0.1,0.01,0.01,0.1,0.1]\n",
        "        hidden_layers = [2,2,2,2,2,2,2,2,2,2,2,2,\\\n",
        "                            3,3,3,3,3,3,3,3,3,3,3,3]\n",
        "        max_iter=[100,200,100,200,100,200,100,200,100,200,100,200,\\\n",
        "                    100,200,100,200,100,200,100,200,100,200,100,200]\n",
        "        temp = {'activation' : activations, 'learning_rate' : learning_rate, 'Hidden_layers' : hidden_layers, 'max_iter' : max_iter, \\\n",
        "                'MSE_train' : self.MSE_train, 'MSE_test' : self.MSE_test,'r2_train' : self.r2_train, 'r2_test' : self.r2_test}\n",
        "\n",
        "        table = pd.DataFrame(data = temp)\n",
        "\n",
        "        print(\"MSE Train: \", self.MSE_train)\n",
        "        print(\"MSE Test: \", self.MSE_test)\n",
        "        print(\"R2 Train: \", self.r2_train)\n",
        "        print(\"R2 Test: \", self.r2_test)\n",
        "\n",
        "        return table\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    neural_network = NeuralNet(\"letter-recognition.data\") # put in path to your file\n",
        "    neural_network.preprocess()\n",
        "    table = neural_network.train_evaluate()\n",
        "\n",
        "    # Plot the model history for each model in a single plot\n",
        "    # model history is a plot of accuracy vs number of epochs\n",
        "    # you may want to create a large sized plot to show multiple lines\n",
        "    # in a same figure.\n",
        "\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='red', linewidth=2,label='logistic_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='olive', linewidth=2,label = 'logistic_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='blue', linewidth=2,label = 'logistic_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='orange',linewidth=2, label = 'logistic_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc = 'upper right')\n",
        "    plt.show()\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='red', linewidth=2,label='logistic_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='olive', linewidth=2,label = 'logistic_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='blue', linewidth=2,label = 'logistic_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='logistic')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='orange',linewidth=2, label = 'logistic_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc = 'upper right')\n",
        "    plt.show()\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='black', linewidth=2, label = 'relu_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='brown', linewidth=2, label = 'relu_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='violet', linewidth=2, label = 'relu_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='green', linewidth=2, label = 'relu_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc = 'upper right')\n",
        "    plt.show()\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='black', linewidth=2, label = 'relu_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='brown', linewidth=2, label = 'relu_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='violet', linewidth=2, label = 'relu_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='relu')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='green', linewidth=2, label = 'relu_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc = 'upper right')\n",
        "    plt.show()\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='yellow', linewidth=2, label = 'tanh_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='purple', linewidth=2, label = 'tanh_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='pink', linewidth=2, label = 'tanh_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_train', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='olive', linewidth=2, label = 'tanh_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.01)&(table['Hidden_layers']==2)], markersize=12, color='yellow', linewidth=2, label = 'tanh_0.01_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.01)&(table['Hidden_layers']==3)], marker='', color='purple', linewidth=2, label = 'tanh_0.01_3')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.1)&(table['Hidden_layers']==2)], markersize=12, color='pink', linewidth=2, label = 'tanh_0.1_2')\n",
        "    plt.plot( 'max_iter', 'MSE_test', data=table.loc[(table['activation']=='tanh')&(table['learning_rate']==0.1)&(table['Hidden_layers']==3)], marker='', color='olive', linewidth=2, label = 'tanh_0.1_3')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rbb7JJZASpX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}